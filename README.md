
# **YOLOv5 med COCO-dataset f칬r Objektigenk칛nning**

---

## **Projektbeskrivning**
Det h칛r projektet implementerar en avancerad tr칛ningspipeline f칬r objektigenk칛nning med hj칛lp av YOLOv5-modellen och COCO-datasetet. M친let 칛r att skapa en robust och effektiv l칬sning f칬r realtidsobjektigenk칛nning som kan identifiera och klassificera objekt i bilder med h칬g precision och snabbhet.

Projektet utvecklades fr친n en ursprunglig plan att anv칛nda enklare dataset och modeller som MobileNet och CIFAR-10. Under arbetets g친ng ins친g jag att en mer avancerad metod skulle ge mig st칬rre l칛randem칬jligheter och en djupare f칬rst친else f칬r datorseende och tr칛ningspipelines.

**Projektet m칬ter f칬ljande m친l:**
- Skriva v칛ldokumenterad och l칛ttl칛st kod.
- Motivera val av modeller och dataset.
- Implementera effektiv Pythonkod med robust felhantering.
- Utforska och dokumentera f칬rb칛ttringsm칬jligheter.

---

## **Motivering av val**

### **Val av algoritm: YOLOv5**
YOLOv5 valdes eftersom det erbjuder en optimal balans mellan snabbhet och noggrannhet, vilket g칬r den idealisk f칬r realtidsapplikationer. Med dess modul칛ra design och omfattande dokumentation var YOLOv5 det b칛sta valet f칬r att implementera en robust tr칛ningspipeline och l칛ra mig hur avancerade modeller fungerar.

### **Val av dataset: COCO**
COCO-datasetet (Common Objects in Context) 칛r en industristandard med 칬ver 80 objektklasser. Jag valde COCO eftersom:
- **H칬gkvalitativ data**: Datasetet inneh친ller detaljerade annoteringar och m친ngsidiga objekt i olika milj칬er.
- **Relevans**: COCO anv칛nds ofta f칬r benchmarking av objektigenk칛nningsmodeller, vilket g칬r det m칬jligt att j칛mf칬ra prestanda med andra l칬sningar.

---

## **Projektm친l**
Projektet syftar till att:
1. Implementera en avancerad tr칛ningspipeline med YOLOv5 och COCO-datasetet.
2. F칬rst친 och hantera datasetf칬rberedelser och felhantering i AI-projekt.
3. Optimera tr칛ningsparametrar f칬r att f칬rb칛ttra modellens prestanda.
4. Exportera modellen i ONNX-format f칬r bredare kompatibilitet.

---

## **Projektstruktur**

### **1. Datasetf칬rberedelser**
- Automatisk nedladdning och packning av COCO128, en mindre version av COCO.
- Verifiering av datasetstruktur f칬r att s칛kerst칛lla att alla n칬dv칛ndiga filer 칛r p친 plats.
- Generering av en `dataset.yaml`-fil f칬r att definiera tr칛nings- och valideringsv칛gar samt objektklasser.

### **2. Tr칛ningspipeline**
- **Parametrar**:
  - Bildstorlek: 640x640 pixlar.
  - Batchstorlek: 16.
  - Antal epoch: 50.
  - Optimerare: AdamW.
- Dynamisk validering av indata och tr칛ningsparametrar f칬r att s칛kerst칛lla korrekthet.
- Loggning av tr칛ningsresultat, inklusive precision (P), recall (R), och mean Average Precision (mAP).

### **3. Testning och visualisering**
- Modellen testas med nya bilder f칬r att generera prediktioner.
- Annoterade bilder sparas och analyseras f칬r utv칛rdering.

### **4. Export och distribution**
- Export av den tr칛nade modellen till ONNX-format f칬r att m칬jligg칬ra vidare anv칛ndning i olika applikationer.

---

## **Kod och Implementering**

Projektets implementation finns i en Jupyter Notebook-fil som inneh친ller all kod f칬r datasetf칬rberedelser, tr칛ningspipeline, testning och export. Du kan komma 친t notebooken direkt via l칛nken nedan:

- 游늭 **[ITHS_Projekt_AntonSme.ipynb](https://github.com/antonsmedberg/projekt-del-2-Ai/blob/main/ITHS_Projekt_AntonSme.ipynb)**

### **Notebook-inneh친ll**
1. **Initialisering och beroenden**: Installation av YOLOv5 och n칬dv칛ndiga bibliotek.
2. **Datasetf칬rberedelser**: Automatisk nedladdning och verifiering av COCO128.
3. **Modelltr칛ning**: Implementering av tr칛ningsloop och loggning av resultat.
4. **Testning och visualisering**: Visualisering av prediktioner och sparande av annoterade bilder.
5. **Export till ONNX**: Export av den tr칛nade modellen f칬r vidare anv칛ndning.

---

## **Kodkvalitet och Felhantering**

Projektet fokuserar p친 att uppr칛tth친lla h칬g kodkvalitet genom:
- **Modularisering**: Funktioner och moduler 칛r tydligt definierade f칬r b칛ttre l칛sbarhet och underh친ll.
- **Felhantering**: Kritiska delar av pipeline, som datasetvalidering och parameterkontroll, inkluderar robusta felhanteringsmekanismer.
- **Effektivitet**: Pipeline anv칛nder GPU-acceleration d칛r det 칛r m칬jligt f칬r att maximera prestandan.

---

## **Analys och F칬rb칛ttringsm칬jligheter**

### **Vad jag har l칛rt mig**
- Hur YOLOv5:s arkitektur fungerar och kan anpassas f칬r olika dataset.
- Vikten av datavalidering och robust felhantering f칬r att f칬rb칛ttra stabiliteten i en tr칛ningspipeline.
- Hur man optimerar tr칛ningsparametrar f칬r att uppn친 en bra balans mellan snabbhet och noggrannhet.

### **F칬rb칛ttringsm칬jligheter**
1. **Distribuerad tr칛ning**: Implementera st칬d f칬r multi-GPU f칬r att f칬rb칛ttra tr칛ningshastigheten.
2. **Ut칬kat dataset**: Anv칛nd hela COCO-datasetet ist칛llet f칬r COCO128 f칬r b칛ttre generalisering.
3. **Avancerad optimering**: Utforska tekniker som mixed precision och kvantisering f칬r att minska latens och resursf칬rbrukning.

---

## **Resultat och Reflektion**

### **Resultat**
- Modellen uppn친dde en genomsnittlig precision (mAP50) p친 78% p친 COCO128, vilket 칛r konkurrenskraftigt f칬r datasetets storlek.
- Annoterade resultat sparades och analyserades framg친ngsrikt.
- Modellen exporterades till ONNX-format utan problem.

### **Reflektion**
Projektet har gett mig en djupare f칬rst친else f칬r avancerade datorseendetekniker och hur man bygger robusta och skalbara AI-l칬sningar. Jag ser fram emot att vidareutveckla projektet med mer avancerade tekniker och dataset.

---

## **Framtida Arbete**
1. **Generaliseringsf칬rb칛ttring**: Ut칬ka datasetet och tr칛na modellen p친 fler kategorier och st칬rre datam칛ngder.
2. **Produktion**: Implementera st칬d f칬r TensorRT f칬r att f칬rb칛ttra prestandan i produktionsmilj칬er.
3. **Semi-supervised learning**: Utforska oannoterade data f칬r att f칬rb칛ttra tr칛ningsprocessen och minska behovet av omfattande annotering.

---

